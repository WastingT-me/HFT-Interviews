{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Libs"
      ],
      "metadata": {
        "id": "D9PnCw89xB3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars"
      ],
      "metadata": {
        "id": "FaLy1NnzwQaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NtI8gZmZwP2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.Config.set_tbl_rows(10)\n",
        "pl.Config.set_tbl_cols(None)"
      ],
      "metadata": {
        "id": "YWBCl139xAu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Load"
      ],
      "metadata": {
        "id": "4cZ1aX5HxEoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "410cot0ewZS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['ServerTimestamp [epoch]',\n",
        "           'MarketTimestamp [epoch]',\n",
        "           'ServerTimestamp [datatime, us]',\n",
        "           'MarketTimestamp [datatime,us]',\n",
        "           'Mdtype',\n",
        "           '[price;qty;nborders] ask 0',\n",
        "           '[price;qty;nborders] ask 1',\n",
        "           '[price;qty;nborders] ask 2',\n",
        "           '[price;qty;nborders] ask 3',\n",
        "           '[price;qty;nborders] ask 4',\n",
        "           '[price;qty;nborders] ask 5',\n",
        "           '[price;qty;nborders] ask 6',\n",
        "           '[price;qty;nborders] ask 7',\n",
        "           '[price;qty;nborders] ask 8',\n",
        "           '[price;qty;nborders] ask 9',\n",
        "           'M',\n",
        "           '[price;qty;nborders] bid 0',\n",
        "           '[price;qty;nborders] bid 1',\n",
        "           '[price;qty;nborders] bid 2',\n",
        "           '[price;qty;nborders] bid 3',\n",
        "           '[price;qty;nborders] bid 4',\n",
        "           '[price;qty;nborders] bid 5',\n",
        "           '[price;qty;nborders] bid 6',\n",
        "           '[price;qty;nborders] bid 7',\n",
        "           '[price;qty;nborders] bid 8',\n",
        "           '[price;qty;nborders] bid 9',\n",
        "           'Obflag',\n",
        "           'ftflagMSBid ',\n",
        "           'ftflagMSAsk ',\n",
        "           'ftflagTLSell ',\n",
        "           'ftflagTLBuy ',\n",
        "           'Stream ',\n",
        "           'Revision ']"
      ],
      "metadata": {
        "id": "issOqv-rwWnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pl.read_csv(\"/content/drive/MyDrive/Quant/dataset_test/Local#FAST_CURR_MD#MOEX_CURR#CETS#USDCNY_TOM.2023-08-14.gz\",\n",
        "                 compression='gzip',\n",
        "                 has_header=False,\n",
        "                 new_columns=columns)"
      ],
      "metadata": {
        "id": "DV6DQN1Twdob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ],
      "metadata": {
        "id": "x4Z0YO9Mw9SU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequency"
      ],
      "metadata": {
        "id": "ck_csVbXyQqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Frequency_data = df.filter((pl.col('Mdtype') == 0) | (pl.col('Mdtype') == 2)).select(['ServerTimestamp [datatime, us]', 'Stream '])\n",
        "\n",
        "Frequency_data = Frequency_data.with_columns(\n",
        "    pl.col('ServerTimestamp [datatime, us]').str.strptime(pl.Datetime, fmt='%Y-%m-%d %H:%M:%S.%f')\n",
        ")\n",
        "\n",
        "Frequency_data = Frequency_data.sort('ServerTimestamp [datatime, us]').with_columns(\n",
        "    (pl.col('ServerTimestamp [datatime, us]') - pl.col('ServerTimestamp [datatime, us]').shift(1)).dt.seconds().alias('TimeDiff')\n",
        ")\n",
        "\n",
        "Frequency_data = Frequency_data.with_columns([\n",
        "    pl.col('ServerTimestamp [datatime, us]').dt.hour().alias('Hour'),\n",
        "    pl.col('ServerTimestamp [datatime, us]').dt.minute().alias('Minute'),\n",
        "    pl.col('ServerTimestamp [datatime, us]').dt.second().alias('Second')\n",
        "])"
      ],
      "metadata": {
        "id": "6C_fUxlOwfgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.strptime('10:00:00', '%H:%M:%S').time()\n",
        "end_time = datetime.strptime('18:40:00', '%H:%M:%S').time()\n",
        "filtered_data = Frequency_data.filter(\n",
        "    (pl.col('ServerTimestamp [datatime, us]').dt.time() >= start_time) &\n",
        "    (pl.col('ServerTimestamp [datatime, us]').dt.time() <= end_time)\n",
        ")\n",
        "\n",
        "frequency = filtered_data.groupby(['Hour', 'Minute', 'Second']).agg(pl.count().alias('count'))\n",
        "\n",
        "frequency = frequency.with_columns(\n",
        "    (pl.col('Hour').cast(pl.Utf8) + ':' +\n",
        "     pl.col('Minute').cast(pl.Utf8).zfill(2) + ':' +\n",
        "     pl.col('Second').cast(pl.Utf8).zfill(2)).alias('Time')\n",
        ").drop(['Hour', 'Minute', 'Second']).rename({'Time': 'index'})"
      ],
      "metadata": {
        "id": "N2SMMMzpwnis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_time_range(start_time, end_time, interval_minutes):\n",
        "    start_dt = datetime.strptime(start_time, '%H:%M:%S')\n",
        "    end_dt = datetime.strptime(end_time, '%H:%M:%S')\n",
        "    interval = timedelta(minutes=interval_minutes)\n",
        "    current_time = start_dt\n",
        "    times = []\n",
        "    while current_time <= end_dt:\n",
        "        times.append(current_time)\n",
        "        current_time += interval\n",
        "    return times"
      ],
      "metadata": {
        "id": "lh0l9X4YwyTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_str = '10:00:00'\n",
        "end_str = '18:40:00'\n",
        "interval = 20\n",
        "\n",
        "tick_positions = create_time_range(start_str, end_str, interval)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(frequency['index'], frequency['count'], color='blue', linewidth=1, linestyle='-', alpha=0.8)\n",
        "plt.title('Частота обновлений данных ОВ за каждую секунду', fontsize=16, pad=20)\n",
        "plt.xlabel('Время', fontsize=14, labelpad=15)\n",
        "plt.ylabel('Частота обновлений', fontsize=14, labelpad=15)\n",
        "\n",
        "# Set custom x-axis formatter to display only HH:MM:SS\n",
        "plt.gca().xaxis.set_major_formatter(DateFormatter('%H:%M:%S'))\n",
        "# Manually set x-axis ticks\n",
        "plt.gca().set_xticks(tick_positions)\n",
        "\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FhTEHaVEwuYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance"
      ],
      "metadata": {
        "id": "485JZhNeyUP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n% переданной информации = $(1 - \\frac{n}{100})$ квантиль времени обновления / 2 (в сторону получателя и обратно):"
      ],
      "metadata": {
        "id": "RdvHWophX0-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Оценка расстояния от сервера Московской биржи до аккаунта пользователя.\n",
        "\n",
        "Для оценки расстояния от сервера Московской биржи до аккаунта пользователя можно использовать информацию о времени задержки передачи данных (RTT) и скорости света в оптическом волокне. Сигналы в оптическом волокне распространяются со скоростью, которая составляет примерно $\\frac{2}{3}$ от скорости света в вакууме.\n",
        "\n",
        "#### Данные для расчета:\n",
        "- **Время туда и обратно (RTT):** 7 микросекунд (мкс)\n",
        "- **Скорость света в вакууме:** \\($c = 3 \\times 10^8$\\) м/с\n",
        "- **Коэффициент преломления оптического волокна:** \\($n \\approx 1.5$\\) что означает, что скорость света в оптическом волокне составляет $\\frac{c}{1.5}$\n",
        "\n",
        "#### Шаги для расчета:\n",
        "\n",
        "1. **Определяем скорость света в оптическом волокне:**\n",
        "   \\begin{align}\n",
        "   c_{\\text{волокно}} = \\frac{3 \\times 10^8\\ \\text{м/с}}{1.5} = 2 \\times 10^8\\ \\text{м/с}\n",
        "   \\end{align}\n",
        "\n",
        "2. **Время передачи сигнала в одну сторону:**\n",
        "   \\begin{align}\n",
        "   t_{\\text{один путь}} = \\frac{7 \\times 10^{-6}\\ \\text{сек}}{2} = 3.5 \\times 10^{-6}\\ \\text{сек}\n",
        "   \\end{align}\n",
        "\n",
        "3. **Расчет расстояния:**\n",
        "   \\begin{align}\n",
        "   d = t_{\\text{один путь}} \\times c_{\\text{волокно}} = 700\\ \\text{м}\n",
        "   \\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "KyfCvs1CVJ9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of quantile values from 0.01 to 0.99\n",
        "quantiles = np.linspace(0.01, 0.99, 99)\n",
        "time_quantiles = Frequency_data['TimeDiff'].quantile(quantiles).to_numpy() / 2\n",
        "\n",
        "c = 3 * 10**8  # speed of light in a vacuum (m/s)\n",
        "n = 1.5  # refractive index of optical fiber\n",
        "c_fiber = c / n  # speed of light in optical fiber (m/s)\n",
        "\n",
        "# Calculate the distance for each time value (using quantile values)\n",
        "distance_quantiles = time_quantiles * c_fiber\n",
        "\n",
        "# Calculate the percentage of information loss\n",
        "loss_percent = 100 * (1 - quantiles)\n",
        "\n",
        "# Create labels for the X-axis: (time, information loss)\n",
        "x_labels = [f\"{t:.6f} sec\\n{loss:.1f}% information\" for t, loss in zip(time_quantiles, loss_percent)]\n",
        "\n",
        "plt.figure(figsize=(40, 16))\n",
        "plt.plot(range(len(time_quantiles)), distance_quantiles, marker='o', color='blue', linewidth=2, markersize=4)\n",
        "plt.title('Зависимость возможного расстояния от % переданной информации', fontsize=16)\n",
        "plt.xlabel('Время (секунды), Переданная информация (%)', fontsize=14)\n",
        "plt.ylabel('Расстояние (метры)', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.yscale('log')\n",
        "plt.xticks(ticks=range(len(time_quantiles)), labels=x_labels, rotation=45, ha='right', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z-_Jb-w8Zj5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2"
      ],
      "metadata": {
        "id": "9v9OtnPHxHzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Mdtype is 1\n",
        "data = df.filter(pl.col('Mdtype') == 1)\n",
        "\n",
        "# Convert ServerTimestamp to datetime\n",
        "data = data.with_column(pl.col('ServerTimestamp [datatime, us]').str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\"))\n",
        "\n",
        "# Filter data based on time range\n",
        "start_time = datetime.strptime('10:00:00', '%H:%M:%S').time()\n",
        "end_time = datetime.strptime('18:40:00', '%H:%M:%S').time()\n",
        "\n",
        "filtered_data = data.filter(\n",
        "    (pl.col('ServerTimestamp [datatime, us]').dt.time() >= start_time) &\n",
        "    (pl.col('ServerTimestamp [datatime, us]').dt.time() <= end_time)\n",
        ")\n",
        "\n",
        "# Convert the column to integer and determine the side of the trade\n",
        "filtered_data = filtered_data.with_columns([\n",
        "    pl.col('[price;qty;nborders] ask 3').cast(pl.Int32),\n",
        "    pl.when(pl.col('[price;qty;nborders] ask 3') == 1).then('buy').otherwise('sell').alias('side')\n",
        "])\n",
        "\n",
        "# Determine TradeID\n",
        "filtered_data = filtered_data.with_column(\n",
        "    ((pl.col('MarketTimestamp [epoch]').shift(1) != pl.col('MarketTimestamp [epoch]')) |\n",
        "     (pl.col('side').shift(1) != pl.col('side')))\n",
        "    .cumsum()\n",
        "    .alias('TradeID')\n",
        ")\n",
        "\n",
        "# Extract the quantity\n",
        "filtered_data = filtered_data.with_column(\n",
        "    pl.col('[price;qty;nborders] ask 0').cast(pl.Float64).alias('Qty')\n",
        ")\n",
        "\n",
        "# Group by TradeID and sum the quantities\n",
        "trade_sizes = filtered_data.groupby('TradeID').agg(\n",
        "    pl.col('Qty').sum().alias('TotalQty')\n",
        ")"
      ],
      "metadata": {
        "id": "RHzlMFkLxIre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate statistics\n",
        "mean_qty = trade_sizes['TotalQty'].mean()\n",
        "stddev_qty = trade_sizes['TotalQty'].std()\n",
        "median_qty = trade_sizes['TotalQty'].median()\n",
        "percentiles = trade_sizes['TotalQty'].quantile([0.6, 0.7, 0.8, 0.9])\n",
        "\n",
        "percentile_pairs = [(f\"{int(p*100)}%\", int(v)) for p, v in zip([0.6, 0.7, 0.8, 0.9], percentiles)]\n",
        "\n",
        "print(\"Mean:\", mean_qty)\n",
        "print(\"StdDev:\", stddev_qty)\n",
        "print(\"Median:\", median_qty)\n",
        "print(\"\\nPercentiles.\")\n",
        "for pair in percentile_pairs:\n",
        "    print(f\"{pair[0]}th Percentile: {pair[1]:.2f}\")"
      ],
      "metadata": {
        "id": "hB4vxdeg06K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probabilities(filtered_data, trade_sizes, threshold):\n",
        "    # Filter trades by quantity threshold\n",
        "    mask = trade_sizes.filter(pl.col('TotalQty') >= threshold)\n",
        "\n",
        "    # Filter the original data by TradeID\n",
        "    filtered = filtered_data.filter(pl.col('TradeID').is_in(mask['TradeID']))\n",
        "\n",
        "    # Compare the current side with the previous one\n",
        "    filtered = filtered.with_columns([\n",
        "        pl.col('side').shift(1).alias('prev_side'),\n",
        "        (pl.col('side') == pl.col('prev_side')).alias('side_match')\n",
        "    ])\n",
        "\n",
        "    # Count matches and calculate probability\n",
        "    matching_sides = filtered['side_match'].sum()\n",
        "    total_trades = filtered.height\n",
        "    probability = matching_sides / total_trades if total_trades > 0 else 0\n",
        "    return probability"
      ],
      "metadata": {
        "id": "y0EsUd6g06pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate probabilities\n",
        "prob_mean = calculate_probabilities(filtered_data, trade_sizes, mean_qty)\n",
        "prob_median = calculate_probabilities(filtered_data, trade_sizes, median_qty)\n",
        "prob_mean_plus_stddev = calculate_probabilities(filtered_data, trade_sizes, mean_qty + stddev_qty)\n",
        "\n",
        "print(f\"Probability(Qty >= mean): {prob_mean:.4f}\")\n",
        "print(f\"Probability(Qty >= median): {prob_median:.4f}\")\n",
        "print(f\"Probability(Qty >= mean + stddev): {prob_mean_plus_stddev:.4f}\")"
      ],
      "metadata": {
        "id": "3Lqs__1l08b7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}